{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCVを使った画像処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "req.urlretrieve(url,\"test.png\")\n",
    "\n",
    "\n",
    "# OpenCVで読み込む\n",
    "import cv2\n",
    "img = cv2.imread(\"test.png\")\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"test.png\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite(\"output.png\",img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のリサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"test.png\")\n",
    "\n",
    "#画像の読み込み\n",
    "im2 = cv2.resize(img,(600,300))\n",
    "\n",
    "cv2.imwrite(\"output-resize.png\", im2)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(cv2.cvtColor(im2,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像の切り取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"test.png\")\n",
    "\n",
    "#画像の一部をきりとる\n",
    "im2 = img[150:450,150:450]\n",
    "\n",
    "#画像のリサイズ\n",
    "im2 = cv2.resize(im2,(400,400))\n",
    "\n",
    "cv2.imwrite(\"cut-resize.png\", im2)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(cv2.cvtColor(im2,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#顔検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# カスケードファイルを指定して検出器を作成\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "#画像を読み込んでグレイスケールにする\n",
    "img = cv2.imread(\"girl.jpg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 顔認識を実行\n",
    "face_list = cascade.detectMultiScale(img_gray, minSize=(150,150))\n",
    "\n",
    "# 結果を確認\n",
    "if len(face_list) == 0:\n",
    "    print(\"失敗\")\n",
    "    quit()\n",
    "\n",
    "#認識した部分に印をつける\n",
    "for (x,y,w,h) in face_list:\n",
    "    print(\"顔の座標=\",x,y,w,h)\n",
    "    red = (0,0,255)\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h) ,red, thickness=10)\n",
    "\n",
    "#画像を出力\n",
    "cv2.imwrite(\"face-detect.png\", img)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顔にモザイクをかける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(img,rect,size):\n",
    "    (x1,y1,x2,y2) = rect\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    i_rect = img[y1:y2, x1:x2]\n",
    "    \n",
    "    i_small = cv2.resize(i_rect, (size,size))\n",
    "    i_mos = cv2.resize(i_small, (w,h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    img2 = img.copy()\n",
    "    img2[y1:y2, x1:x2] = i_mos\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#from mosaic import mosaic as mosaic\n",
    "\n",
    "# カスケードファイルを指定して検出器を作成\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "#画像を読み込んでグレイスケールにする\n",
    "img = cv2.imread(\"girl.jpg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 顔検出を実行\n",
    "face_list = cascade.detectMultiScale(img_gray, minSize=(150,150))\n",
    "\n",
    "# 結果を確認\n",
    "if len(face_list) == 0:\n",
    "    print(\"失敗\")\n",
    "    quit()\n",
    "\n",
    "#認識した部分にモザイクをかける\n",
    "for (x,y,w,h) in face_list:\n",
    "    img = mosaic(img,(x,y,x+w,y+h),10)\n",
    "    \n",
    "#画像を出力\n",
    "cv2.imwrite(\"face-mosaic.png\", img)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意: OpenCVの顔検出は横顔や傾きに弱いらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動画解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # カメラの画像を読み込む\n",
    "    _,frame = cap.read()\n",
    "    # 画像を縮小表示する\n",
    "    frame = cv2.resize(frame, (500,300))\n",
    "    #ウィンドウ画像を出力\n",
    "    cv2.imshow('OpeCV Web Camera', frame)\n",
    "    # ESCかEnterキーが押されたらループを抜ける\n",
    "    k = cv2.waitKey(1) # 1msec\n",
    "    if k == 27 or k == 13: break\n",
    "        \n",
    "cap.release() # カメラを解放\n",
    "cv2.destroyAllWindows() # ウィンドウを破棄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像に動きがあった部分を抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "img_last = None # 前回の画像を記憶する変数\n",
    "green = (0,255,0)\n",
    "\n",
    "while True:\n",
    "    # カメラの画像を読み込む\n",
    "    _,frame = cap.read()\n",
    "    # 画像を縮小表示する\n",
    "    frame = cv2.resize(frame, (500,300))\n",
    "    #白黒画像に変換\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "    img_b = cv2.threshold(gray, 100,255, cv2.THRESH_BINARY)[1]\n",
    "    # 差分を確認する\n",
    "    if img_last is None:\n",
    "        img_last = img_b\n",
    "        continue\n",
    "    frame_diff = cv2.absdiff(img_last, img_b)\n",
    "    cnts = cv2.findContours(frame_diff,\n",
    "            cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "    # 差分があった点を画面に描く\n",
    "    for pt in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(pt)\n",
    "        if w < 30: continue # 小さな変更点は無視\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), green, 2)\n",
    "   \n",
    "    # 今回のフレームを保存\n",
    "    img_last = img_b\n",
    "    # 画面に表示\n",
    "    cv2.imgshow(\"DIff Camera\", frame)\n",
    "    cv2.imgshow(\"diff data\", frame_diff)\n",
    "    if cv2.waitKey(1) == 13: break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
